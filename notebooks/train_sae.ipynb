{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/sae/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.3.1', '4.43.3', '12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 12:46:51 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-08-21 12:46:51 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "2024-08-21 12:46:52 datasets INFO     PyTorch version 2.3.1 available.\n",
      "2024-08-21 12:46:52 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:52 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:52 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2024-08-21 12:46:52 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/wikimedia/wikipedia/wikimedia/wikipedia.py HTTP/11\" 404 0\n",
      "2024-08-21 12:46:52 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:52 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:52 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/wikimedia/wikipedia/resolve/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/README.md HTTP/11\" 200 0\n",
      "2024-08-21 12:46:52 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/wikimedia/wikipedia/resolve/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/.huggingface.yaml HTTP/11\" 404 0\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=wikimedia/wikipedia HTTP/11\" 200 None\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/tree/b04c8d1ceb2f5cd4588862100d08de323dccfbaa?recursive=False&expand=False HTTP/11\" 200 32709\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/wikimedia/wikipedia/paths-info/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 236\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/tree/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/20231101.ab?recursive=False&expand=False HTTP/11\" 200 245\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/wikimedia/wikipedia/resolve/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/dataset_infos.json HTTP/11\" 404 0\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/wikimedia/wikipedia/paths-info/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 244\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/tree/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/20231101.en?recursive=False&expand=False HTTP/11\" 200 10169\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:53 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164230\n",
      "2024-08-21 12:46:54 filelock DEBUG    Attempting to acquire lock 139763024313296 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikimedia___wikipedia_20231101.en_0.0.0_b04c8d1ceb2f5cd4588862100d08de323dccfbaa.lock\n",
      "2024-08-21 12:46:54 filelock DEBUG    Lock 139763024313296 acquired on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikimedia___wikipedia_20231101.en_0.0.0_b04c8d1ceb2f5cd4588862100d08de323dccfbaa.lock\n",
      "2024-08-21 12:46:54 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/dataset_info.json\n",
      "2024-08-21 12:46:54 filelock DEBUG    Attempting to release lock 139763024313296 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikimedia___wikipedia_20231101.en_0.0.0_b04c8d1ceb2f5cd4588862100d08de323dccfbaa.lock\n",
      "2024-08-21 12:46:54 filelock DEBUG    Lock 139763024313296 released on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikimedia___wikipedia_20231101.en_0.0.0_b04c8d1ceb2f5cd4588862100d08de323dccfbaa.lock\n",
      "2024-08-21 12:46:54 filelock DEBUG    Attempting to acquire lock 139763282802960 on /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa_builder.lock\n",
      "2024-08-21 12:46:54 filelock DEBUG    Lock 139763282802960 acquired on /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa_builder.lock\n",
      "2024-08-21 12:46:54 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/dataset_info.json\n",
      "2024-08-21 12:46:54 filelock DEBUG    Attempting to release lock 139763282802960 on /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa_builder.lock\n",
      "2024-08-21 12:46:54 filelock DEBUG    Lock 139763282802960 released on /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa_builder.lock\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "wiki = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(wiki[\"train\"]))\n",
    "# wiki[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/roneneldan/TinyStories HTTP/11\" 200 1957\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/roneneldan/TinyStories/roneneldan/TinyStories.py HTTP/11\" 404 0\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/roneneldan/TinyStories HTTP/11\" 200 1957\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/README.md HTTP/11\" 200 0\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/.huggingface.yaml HTTP/11\" 404 0\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=roneneldan/TinyStories HTTP/11\" 200 None\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/roneneldan/TinyStories/revision/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64 HTTP/11\" 200 1957\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/roneneldan/TinyStories/tree/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64?recursive=False&expand=False HTTP/11\" 200 1797\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/roneneldan/TinyStories/paths-info/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64 HTTP/11\" 200 218\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/roneneldan/TinyStories/tree/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/data?recursive=False&expand=False HTTP/11\" 200 1292\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/roneneldan/TinyStories/paths-info/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64 HTTP/11\" 200 218\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:54 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:55 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/roneneldan/TinyStories/revision/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64 HTTP/11\" 200 1957\n",
      "2024-08-21 12:46:55 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/roneneldan/TinyStories/revision/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64 HTTP/11\" 200 1957\n",
      "2024-08-21 12:46:55 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/roneneldan/TinyStories/revision/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64 HTTP/11\" 200 1957\n",
      "2024-08-21 12:46:55 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/roneneldan/TinyStories/revision/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64 HTTP/11\" 200 1957\n",
      "2024-08-21 12:46:55 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/roneneldan/TinyStories/paths-info/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64 HTTP/11\" 200 218\n",
      "2024-08-21 12:46:55 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 12:46:55 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/roneneldan/TinyStories/resolve/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/dataset_infos.json HTTP/11\" 404 0\n",
      "2024-08-21 12:46:55 filelock DEBUG    Attempting to acquire lock 139766611065808 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_roneneldan___tiny_stories_default_0.0.0_f54c09fd23315a6f9c86f9dc80f725de7d8f9c64.lock\n",
      "2024-08-21 12:46:55 filelock DEBUG    Lock 139766611065808 acquired on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_roneneldan___tiny_stories_default_0.0.0_f54c09fd23315a6f9c86f9dc80f725de7d8f9c64.lock\n",
      "2024-08-21 12:46:55 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/roneneldan___tiny_stories/default/0.0.0/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/dataset_info.json\n",
      "2024-08-21 12:46:55 filelock DEBUG    Attempting to release lock 139766611065808 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_roneneldan___tiny_stories_default_0.0.0_f54c09fd23315a6f9c86f9dc80f725de7d8f9c64.lock\n",
      "2024-08-21 12:46:55 filelock DEBUG    Lock 139766611065808 released on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_roneneldan___tiny_stories_default_0.0.0_f54c09fd23315a6f9c86f9dc80f725de7d8f9c64.lock\n",
      "2024-08-21 12:46:55 filelock DEBUG    Attempting to acquire lock 139766611082064 on /home/local_arnab/.cache/huggingface/datasets/roneneldan___tiny_stories/default/0.0.0/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64_builder.lock\n",
      "2024-08-21 12:46:55 filelock DEBUG    Lock 139766611082064 acquired on /home/local_arnab/.cache/huggingface/datasets/roneneldan___tiny_stories/default/0.0.0/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64_builder.lock\n",
      "2024-08-21 12:46:55 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/roneneldan___tiny_stories/default/0.0.0/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/dataset_info.json\n",
      "2024-08-21 12:46:55 filelock DEBUG    Attempting to release lock 139766611082064 on /home/local_arnab/.cache/huggingface/datasets/roneneldan___tiny_stories/default/0.0.0/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64_builder.lock\n",
      "2024-08-21 12:46:55 filelock DEBUG    Lock 139766611082064 released on /home/local_arnab/.cache/huggingface/datasets/roneneldan___tiny_stories/default/0.0.0/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64_builder.lock\n"
     ]
    }
   ],
   "source": [
    "tiny = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2119719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'Once upon a time there was a dependable bear who loved having fun. He went on many adventures with his friends and each discovery was full of joy and surprise. One day, he found something he could not accept. His friends were scared, but the bear was brave. He thought carefully and tried to find a way to make things fun again. He worked hard and tried many things. Finally, he came up with a dependable way to solve the problem. All of the animals celebrated and had lots of fun! They thanked the bear for his hard work and accepted his solution. They all lived happily ever after. The end.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tiny[\"train\"]))\n",
    "tiny[\"train\"][5055]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 12:46:56 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "2024-08-21 12:46:56 src.models INFO     loaded model </home/local_arnab/Codes/00_MODEL/EleutherAI/pythia-410m> | size: 875.114 MB | dtype: torch.float16 | device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1024, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# model_name = \"openai-community/gpt2-xl\"\n",
    "# model_name = \"openai-community/gpt2\"\n",
    "model_name = \"EleutherAI/pythia-410m\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_name,\n",
    "    # torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "mt.n_embd, mt.n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt_neox.layers.{}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.layer_name_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 1024)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXSdpaAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
       "  (generator): WrapperModule()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 12:46:56 git.cmd DEBUG    Popen(['git', 'version'], cwd=/home/local_arnab/Codes/sae/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2024-08-21 12:46:56 git.cmd DEBUG    Popen(['git', 'version'], cwd=/home/local_arnab/Codes/sae/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2024-08-21 12:46:56 wandb.docker.auth DEBUG    Trying paths: ['/home/local_arnab/.docker/config.json', '/home/local_arnab/.dockercfg']\n",
      "2024-08-21 12:46:56 wandb.docker.auth DEBUG    No config file found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d_submodule': 1024,\n",
       " 'io': 'out',\n",
       " 'n_ctxs': 300,\n",
       " 'ctx_len': 128,\n",
       " 'refresh_batch_size': 512,\n",
       " 'out_batch_size': 8192,\n",
       " 'device': 'cuda:0'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dictionary_learning import ActivationBuffer\n",
    "from dictionary_learning.training import trainSAE\n",
    "from src.functional import get_module_nnsight\n",
    "\n",
    "submodule = get_module_nnsight(mt, mt.layer_name_format.format(mt.n_layer//2))\n",
    "activation_dim = mt.n_embd\n",
    "dictionary_dim = 4096\n",
    "\n",
    "# data_iter = iter(tiny[\"train\"][:2100000][\"text\"])\n",
    "# data_iter = iter(tiny[\"train\"][:10000][\"text\"])\n",
    "data_iter = iter(wiki[\"train\"][:10000][\"text\"])\n",
    "\n",
    "\n",
    "tiny_buffer = ActivationBuffer(\n",
    "    data_iter,\n",
    "    mt,\n",
    "    submodule,\n",
    "    d_submodule=activation_dim, # output dimension of the model component\n",
    "    n_ctxs=300, # you can set this higher or lower dependong on your available memory\n",
    "    device='cuda:0' # doesn't have to be the same device that you train your autoencoder on\n",
    ") # buffer will return batches of tensors of dimension = submodule's output dimension\n",
    "\n",
    "tiny_buffer.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps = None\n",
    "# for step, act in enumerate(tqdm(tiny_buffer, total=steps)):\n",
    "#     print(step, act.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]You're using a GPTNeoXTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "57it [00:24,  2.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from dictionary_learning.trainers.standard import StandardTrainer\n",
    "from dictionary_learning.dictionary import AutoEncoder\n",
    "\n",
    "# train the sparse autoencoder (SAE)\n",
    "ae = trainSAE(\n",
    "    data = tiny_buffer,\n",
    "    trainer_configs= [{\n",
    "        'trainer' : StandardTrainer,\n",
    "        'dict_class' : AutoEncoder,\n",
    "        'activation_dim' : activation_dim,\n",
    "        'dict_size' : dictionary_dim,\n",
    "        'lr' : 1e-3,\n",
    "        'l1_penalty' : 1e-1,\n",
    "        'warmup_steps' : 10000,\n",
    "        'resample_steps' : None,\n",
    "        'seed' : None,\n",
    "        'wandb_name' : 'StandardTrainer',\n",
    "        'lm_name': mt.name,\n",
    "        'layer': submodule,\n",
    "        'submodule_name': \"residual\",\n",
    "    }],\n",
    "    save_dir=\"trained_saes\",\n",
    "    save_steps=10,\n",
    "\n",
    "    # use_wandb=True,\n",
    "    # wandb_entity=\"dl-homeworks\",\n",
    "    # wandb_project=\"test_sae\",\n",
    "    # log_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary_learning.dictionary import AutoEncoder\n",
    "from src.utils import env_utils\n",
    "\n",
    "ae = AutoEncoder.from_pretrained(\n",
    "    path = os.path.join(\n",
    "        env_utils.DEFAULT_RESULTS_DIR,\n",
    "        \"trained_saes\",\n",
    "        mt.name.split(\"/\")[-1],\n",
    "        \"TinyStories\",\n",
    "        \"trainer_0/ae.pt\"\n",
    "    ),\n",
    "    device='cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (decoder): Linear(in_features=4096, out_features=1024, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1105e-05,  2.0128e-02, -1.5454e-03,  ...,  5.5606e-03,\n",
       "         -1.7302e-02,  1.3566e-02],\n",
       "        [-7.5595e-03, -1.1574e-02, -2.3335e-02,  ...,  2.3730e-02,\n",
       "          3.7004e-04,  1.7028e-02],\n",
       "        [ 5.6901e-04,  2.5539e-02,  4.2656e-03,  ..., -6.8811e-03,\n",
       "         -2.2053e-02,  1.1325e-02],\n",
       "        ...,\n",
       "        [ 6.6162e-04,  2.7501e-02, -1.2707e-02,  ..., -9.0291e-04,\n",
       "          1.4508e-02,  2.9553e-02],\n",
       "        [-1.1730e-02,  2.6030e-02, -2.9809e-03,  ..., -3.8242e-03,\n",
       "         -2.0368e-02, -1.7750e-03],\n",
       "        [ 2.0354e-02,  1.4571e-02,  1.3098e-02,  ..., -1.4957e-03,\n",
       "          2.6515e-03, -9.9766e-03]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.encoder.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
