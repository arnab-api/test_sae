{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/sae/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.4.1', '4.44.2', '12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-15 12:06:58 numexpr.utils INFO     Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2024-10-15 12:06:58 numexpr.utils INFO     NumExpr defaulting to 8 threads.\n",
      "2024-10-15 12:06:58 datasets INFO     PyTorch version 2.4.1 available.\n",
      "2024-10-15 12:06:58 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:06:58 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia HTTP/11\" 200 164229\n",
      "2024-10-15 12:06:58 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2024-10-15 12:06:58 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/wikimedia/wikipedia/wikimedia/wikipedia.py HTTP/11\" 404 0\n",
      "2024-10-15 12:06:58 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia HTTP/11\" 200 164229\n",
      "2024-10-15 12:06:58 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:06:58 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/wikimedia/wikipedia/resolve/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/README.md HTTP/11\" 200 0\n",
      "2024-10-15 12:06:59 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:06:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/wikimedia/wikipedia/resolve/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/.huggingface.yaml HTTP/11\" 404 0\n",
      "2024-10-15 12:06:59 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2024-10-15 12:06:59 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=wikimedia/wikipedia HTTP/11\" 200 None\n",
      "2024-10-15 12:06:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:06:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/tree/b04c8d1ceb2f5cd4588862100d08de323dccfbaa?recursive=False&expand=False HTTP/11\" 200 32709\n",
      "2024-10-15 12:06:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/wikimedia/wikipedia/paths-info/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 236\n",
      "2024-10-15 12:06:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/tree/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/20231101.ab?recursive=False&expand=False HTTP/11\" 200 245\n",
      "2024-10-15 12:06:59 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:06:59 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/wikimedia/wikipedia/resolve/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/dataset_infos.json HTTP/11\" 404 0\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/wikimedia/wikipedia/paths-info/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 244\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/tree/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/20231101.en?recursive=False&expand=False HTTP/11\" 200 10169\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:01 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/wikimedia/wikipedia/revision/b04c8d1ceb2f5cd4588862100d08de323dccfbaa HTTP/11\" 200 164229\n",
      "2024-10-15 12:07:01 filelock DEBUG    Attempting to acquire lock 140699535730832 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikimedia___wikipedia_20231101.en_0.0.0_b04c8d1ceb2f5cd4588862100d08de323dccfbaa.lock\n",
      "2024-10-15 12:07:01 filelock DEBUG    Lock 140699535730832 acquired on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikimedia___wikipedia_20231101.en_0.0.0_b04c8d1ceb2f5cd4588862100d08de323dccfbaa.lock\n",
      "2024-10-15 12:07:01 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/dataset_info.json\n",
      "2024-10-15 12:07:01 filelock DEBUG    Attempting to release lock 140699535730832 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikimedia___wikipedia_20231101.en_0.0.0_b04c8d1ceb2f5cd4588862100d08de323dccfbaa.lock\n",
      "2024-10-15 12:07:01 filelock DEBUG    Lock 140699535730832 released on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_wikimedia___wikipedia_20231101.en_0.0.0_b04c8d1ceb2f5cd4588862100d08de323dccfbaa.lock\n",
      "2024-10-15 12:07:01 filelock DEBUG    Attempting to acquire lock 140699283808656 on /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa_builder.lock\n",
      "2024-10-15 12:07:01 filelock DEBUG    Lock 140699283808656 acquired on /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa_builder.lock\n",
      "2024-10-15 12:07:01 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa/dataset_info.json\n",
      "2024-10-15 12:07:01 filelock DEBUG    Attempting to release lock 140699283808656 on /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa_builder.lock\n",
      "2024-10-15 12:07:01 filelock DEBUG    Lock 140699283808656 released on /home/local_arnab/.cache/huggingface/datasets/wikimedia___wikipedia/20231101.en/0.0.0/b04c8d1ceb2f5cd4588862100d08de323dccfbaa_builder.lock\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "wiki = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(wiki[\"train\"]))\n",
    "# wiki[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(tiny[\"train\"]))\n",
    "# tiny[\"train\"][5055]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-15 12:07:02 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-15 12:07:04 src.models INFO     loaded model </home/local_arnab/Codes/00_MODEL/google/gemma-2-2b> | size: 9972.936 MB | dtype: torch.float32 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "# model_name = \"openai-community/gpt2-xl\"\n",
    "# model_name = \"openai-community/gpt2\"\n",
    "# model_name = \"EleutherAI/pythia-410m\"\n",
    "model_name = \"google/gemma-2-2b\"\n",
    "# model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_name,\n",
    "    # torch_dtype=torch.float16,\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "\n",
    "# lm = LanguageModel(\n",
    "#     model_key=model_name,\n",
    "#     # torch_dtype=torch.float16,\n",
    "#     device_map = \"auto\",\n",
    "#     dispatch=True\n",
    "# )\n",
    "# lm.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # layer_name_format = 'gpt_neox.layers.{}'\n",
    "# layer_name_format = mt.layer_name_format\n",
    "# n_embd = mt.n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.embedder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.functional import get_module_nnsight\n",
    "# from src.functional import prepare_input\n",
    "\n",
    "# prompts = [\n",
    "#     \"A quick brown fox jumps over the lazy\",\n",
    "#     \"The capital of France is\",\n",
    "# ]    \n",
    "# tokens = prepare_input(prompts, tokenizer=mt.tokenizer)\n",
    "\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_tokens = prepare_input(\n",
    "#     prompts, tokenizer=mt.tokenizer,\n",
    "#     # truncation=True, max_length=5,\n",
    "#     padding_side=\"right\",\n",
    "# )\n",
    "\n",
    "# test_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_tokens = prepare_input(\n",
    "#     prompts, tokenizer=mt.tokenizer,\n",
    "#     truncation=True, max_length=5,\n",
    "#     # padding_side=\"left\",\n",
    "# )\n",
    "\n",
    "# test_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.inference_mode():\n",
    "#     with mt.trace(test_tokens) as tr:\n",
    "#         resid_out = get_module_nnsight(mt, layer_name_format.format(3)).output[0].save()\n",
    "#         # input = get_module_nnsight(mt, mt.embedder_name).input.save()\n",
    "#         # resid_in = get_module_nnsight(mt, layer_name_format.format(3)).input.save()\n",
    "#         # output = mt.output.save()\n",
    "\n",
    "# print(resid_out.shape)\n",
    "# # resid_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.inference_mode():\n",
    "#     with mt.trace(\n",
    "#         prompts,\n",
    "#         invoker_args={\"truncation\": True, \"max_length\": 5}\n",
    "#     ) as tr:\n",
    "#         resid_out_2 = get_module_nnsight(mt, layer_name_format.format(3)).output[0].save()\n",
    "#         # input = get_module_nnsight(mt, mt.embedder_name).input.save()\n",
    "#         # resid_in = get_module_nnsight(mt, layer_name_format.format(3)).input.save()\n",
    "#         # output = mt.output.save()\n",
    "\n",
    "# print(resid_out_2.shape)\n",
    "# # resid_out_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.allclose(resid_out, resid_out_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18432"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.n_embd*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-15 12:07:04 git.cmd DEBUG    Popen(['git', 'version'], cwd=/home/local_arnab/Codes/Projects/sae/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2024-10-15 12:07:04 git.cmd DEBUG    Popen(['git', 'version'], cwd=/home/local_arnab/Codes/Projects/sae/notebooks, stdin=None, shell=False, universal_newlines=False)\n",
      "2024-10-15 12:07:04 wandb.docker.auth DEBUG    Trying paths: ['/home/local_arnab/.docker/config.json', '/home/local_arnab/.dockercfg']\n",
      "2024-10-15 12:07:04 wandb.docker.auth DEBUG    No config file found\n",
      "init self.activations.shape=torch.Size([0, 2304])\n",
      "init self.read.shape=torch.Size([0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d_submodule': 2304,\n",
       " 'io': 'out',\n",
       " 'n_ctxs': 32,\n",
       " 'ctx_len': 256,\n",
       " 'refresh_batch_size': 32,\n",
       " 'out_batch_size': 8192,\n",
       " 'device': 'cuda:0'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dictionary_learning import ActivationBuffer\n",
    "from dictionary_learning.training import trainSAE\n",
    "from src.functional import get_module_nnsight\n",
    "\n",
    "submodule = get_module_nnsight(mt, mt.layer_name_format.format(6))\n",
    "activation_dim = mt.n_embd\n",
    "dictionary_dim = 16384\n",
    "\n",
    "# data_iter = iter(tiny[\"train\"][:2100000][\"text\"])\n",
    "# data_iter = iter(tiny[\"train\"][:10000][\"text\"])\n",
    "data_iter = iter(wiki[\"train\"][:1000][\"text\"])\n",
    "\n",
    "\n",
    "tiny_buffer = ActivationBuffer(\n",
    "    data_iter,\n",
    "    mt,\n",
    "    submodule,\n",
    "    d_submodule=activation_dim, \n",
    "    n_ctxs=32, \n",
    "    ctx_len=256,\n",
    "    \n",
    "    refresh_batch_size=32,\n",
    "    device='cuda:0', \n",
    ")\n",
    "\n",
    "tiny_buffer.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "0it [00:03, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([8192, 2304])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "steps = None\n",
    "for step, act in enumerate(tqdm(tiny_buffer, total=steps)):\n",
    "    print(step, act.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import free_gpu_cache\n",
    "\n",
    "free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "! rm -rf trained_saes\n",
    "! rm -rf wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-15 12:07:08 src.utils.experiment_utils INFO     setting all seeds to 1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-15 12:07:09 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "2024-10-15 12:07:09 urllib3.connectionpool DEBUG    https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 1973\n",
      "2024-10-15 12:07:09 urllib3.connectionpool DEBUG    https://api.wandb.ai:443 \"POST /graphql HTTP/11\" 200 381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marnab-api\u001b[0m (\u001b[33mdl-homeworks\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-15 12:07:10 git.cmd DEBUG    Popen(['git', 'cat-file', '--batch-check'], cwd=/home/local_arnab/Codes/Projects/sae, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/local_arnab/Codes/Projects/sae/notebooks/wandb/run-20241015_120710-pdwf6fnq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dl-homeworks/test_sae/runs/pdwf6fnq' target=\"_blank\">run_Tue_Oct_15_12:07:09_2024</a></strong> to <a href='https://wandb.ai/dl-homeworks/test_sae' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dl-homeworks/test_sae' target=\"_blank\">https://wandb.ai/dl-homeworks/test_sae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dl-homeworks/test_sae/runs/pdwf6fnq' target=\"_blank\">https://wandb.ai/dl-homeworks/test_sae/runs/pdwf6fnq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [01:34,  5.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>StandardTrainer-0/frac_variance_explained</td><td>▁   </td></tr><tr><td>StandardTrainer-0/l0</td><td>▁███</td></tr><tr><td>StandardTrainer-0/l2_loss</td><td>▁   </td></tr><tr><td>StandardTrainer-0/loss</td><td>▁   </td></tr><tr><td>StandardTrainer-0/mse_loss</td><td>▁   </td></tr><tr><td>StandardTrainer-0/sparsity_loss</td><td>▁   </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>StandardTrainer-0/frac_variance_explained</td><td>nan</td></tr><tr><td>StandardTrainer-0/l0</td><td>16384</td></tr><tr><td>StandardTrainer-0/l2_loss</td><td>nan</td></tr><tr><td>StandardTrainer-0/loss</td><td>nan</td></tr><tr><td>StandardTrainer-0/mse_loss</td><td>nan</td></tr><tr><td>StandardTrainer-0/sparsity_loss</td><td>nan</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run_Tue_Oct_15_12:07:09_2024</strong> at: <a href='https://wandb.ai/dl-homeworks/test_sae/runs/pdwf6fnq' target=\"_blank\">https://wandb.ai/dl-homeworks/test_sae/runs/pdwf6fnq</a><br/> View project at: <a href='https://wandb.ai/dl-homeworks/test_sae' target=\"_blank\">https://wandb.ai/dl-homeworks/test_sae</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241015_120710-pdwf6fnq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-15 12:08:47 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): o151352.ingest.sentry.io:443\n",
      "2024-10-15 12:08:48 urllib3.connectionpool DEBUG    https://o151352.ingest.sentry.io:443 \"POST /api/4504800232407040/envelope/ HTTP/11\" 200 0\n"
     ]
    }
   ],
   "source": [
    "from dictionary_learning.trainers.standard import StandardTrainer\n",
    "from dictionary_learning.dictionary import AutoEncoder\n",
    "from src.utils.experiment_utils import set_seed\n",
    "\n",
    "set_seed(1234)\n",
    "\n",
    "# train the sparse autoencoder (SAE)\n",
    "ae = trainSAE(\n",
    "    data = tiny_buffer,\n",
    "    trainer_configs= [{\n",
    "        'trainer' : StandardTrainer,\n",
    "        'dict_class' : AutoEncoder,\n",
    "        'activation_dim' : activation_dim,\n",
    "        'dict_size' : dictionary_dim,\n",
    "        'lr' : 1e-3,\n",
    "        'l1_penalty' : 1e-1,\n",
    "        'warmup_steps' : 1000,\n",
    "        'resample_steps' : None,\n",
    "        'seed' : None,\n",
    "        'wandb_name' : 'StandardTrainer',\n",
    "        'lm_name': mt.name,\n",
    "        'layer': submodule,\n",
    "        'submodule_name': \"residual\",\n",
    "    }],\n",
    "    save_dir=\"trained_saes\",\n",
    "    save_steps=10,\n",
    "\n",
    "    use_wandb=True,\n",
    "    wandb_entity=\"dl-homeworks\",\n",
    "    wandb_project=\"test_sae\",\n",
    "    log_steps=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/Codes/Projects/sae/notebooks/../dictionary_learning/dictionary.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = t.load(path)\n"
     ]
    }
   ],
   "source": [
    "from dictionary_learning.dictionary import AutoEncoder\n",
    "from src.utils import env_utils\n",
    "\n",
    "ae = AutoEncoder.from_pretrained(\n",
    "    path = os.path.join(\n",
    "        # env_utils.DEFAULT_RESULTS_DIR,\n",
    "        \"trained_saes\",\n",
    "        # mt.name.split(\"/\")[-1],\n",
    "        # \"TinyStories\",\n",
    "        \"trainer_0/checkpoints/ae_0.pt\"\n",
    "    ),\n",
    "    device='cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2304, out_features=16384, bias=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
