{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/sae/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.3.1', '4.43.3', '12.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import baukit\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from src import functional\n",
    "import numpy as np\n",
    "import logging\n",
    "from src import models\n",
    "\n",
    "from src.utils import logging_utils, env_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__, transformers.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-22 14:46:42 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "2024-08-22 14:46:42 src.models INFO     loaded model </home/local_arnab/Codes/00_MODEL/EleutherAI/pythia-410m> | size: 875.114 MB | dtype: torch.float16 | device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1024, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# model_name = \"openai-community/gpt2-xl\"\n",
    "# model_name = \"openai-community/gpt2\"\n",
    "model_name = \"EleutherAI/pythia-410m\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_name,\n",
    "    # torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "mt.n_embd, mt.n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary_learning import ActivationBuffer\n",
    "from dictionary_learning.training import trainSAE\n",
    "from src.functional import get_module_nnsight\n",
    "from dictionary_learning.dictionary import AutoEncoder\n",
    "\n",
    "submodule = get_module_nnsight(mt, mt.layer_name_format.format(mt.n_layer//2))\n",
    "activation_dim = mt.n_embd\n",
    "dictionary_dim = 4096\n",
    "\n",
    "dataset_name = \"rand_2\"\n",
    "save_dir = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"trained_saes\",\n",
    "    model_name.split(\"/\")[-1],\n",
    "    dataset_name,\n",
    "    \"trainer_0\"\n",
    ")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# rand_ae = AutoEncoder(\n",
    "#     activation_dim=activation_dim,\n",
    "#     dict_size = dictionary_dim\n",
    "# )\n",
    "# torch.save(rand_ae.state_dict(), os.path.join(save_dir, \"ae.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dictionary_learning.dictionary import AutoEncoder\n",
    "from src.utils import env_utils\n",
    "\n",
    "ae = AutoEncoder.from_pretrained(\n",
    "    path = os.path.join(save_dir, \"ae.pt\"),\n",
    "    device='cuda:0'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0104,  0.0311, -0.0214,  ...,  0.0170, -0.0002,  0.0222],\n",
       "        [ 0.0180, -0.0082,  0.0032,  ...,  0.0098,  0.0042,  0.0009],\n",
       "        [ 0.0227,  0.0072,  0.0311,  ...,  0.0126,  0.0057,  0.0223],\n",
       "        ...,\n",
       "        [-0.0273,  0.0209,  0.0192,  ...,  0.0186,  0.0068, -0.0100],\n",
       "        [-0.0156,  0.0038, -0.0150,  ..., -0.0089,  0.0303, -0.0053],\n",
       "        [ 0.0116,  0.0042,  0.0184,  ..., -0.0006, -0.0157, -0.0311]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.encoder.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
