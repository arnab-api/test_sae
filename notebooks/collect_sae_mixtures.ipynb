{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/sae/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 18:01:18 __main__ INFO     torch.__version__='2.3.1', torch.version.cuda='12.1'\n",
      "2024-08-21 18:01:18 __main__ INFO     torch.cuda.is_available()=True, torch.cuda.device_count()=1, torch.cuda.get_device_name()='NVIDIA RTX A6000'\n",
      "2024-08-21 18:01:18 __main__ INFO     transformers.__version__='4.43.3'\n"
     ]
    }
   ],
   "source": [
    "import time, json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "import spacy\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "from src.utils import env_utils\n",
    "from src import functional\n",
    "from datasets import load_dataset\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "logger.info(f\"{torch.__version__=}, {torch.version.cuda=}\")\n",
    "logger.info(f\"{torch.cuda.is_available()=}, {torch.cuda.device_count()=}, {torch.cuda.get_device_name()=}\")\n",
    "logger.info(f\"{transformers.__version__=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 18:01:19 accelerate.utils.modeling INFO     We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "2024-08-21 18:01:20 src.models INFO     loaded model </home/local_arnab/Codes/00_MODEL/EleutherAI/pythia-410m> | size: 1648.227 MB | dtype: torch.float32 | device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from src.models import ModelandTokenizer\n",
    "\n",
    "# model_name = \"openai-community/gpt2-xl\"\n",
    "# model_name = \"openai-community/gpt2\"\n",
    "model_name = \"EleutherAI/pythia-410m\"\n",
    "\n",
    "mt = ModelandTokenizer(\n",
    "    model_key=model_name,\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"roneneldan/TinyStories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (decoder): Linear(in_features=4096, out_features=1024, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dictionary_learning.dictionary import AutoEncoder\n",
    "\n",
    "model_data_dir = os.path.join(\n",
    "    model_name.split(\"/\")[-1],\n",
    "    dataset_name.split(\"/\")[-1],\n",
    ")\n",
    "\n",
    "sae_dir = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"trained_saes\",\n",
    "    model_data_dir,\n",
    "    \"trainer_0/ae.pt\"\n",
    ")\n",
    "\n",
    "sae = AutoEncoder.from_pretrained(\n",
    "    path = sae_dir,\n",
    "    device=mt.device\n",
    ").to(mt.dtype)\n",
    "sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-21 17:00:34 src.utils.experiment_utils INFO     setting all seeds to 123456\n",
      "2024-08-21 17:00:34 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 17:00:34 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/mickume/harry_potter_tiny HTTP/11\" 200 975\n",
      "2024-08-21 17:00:34 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/mickume/harry_potter_tiny/mickume/harry_potter_tiny.py HTTP/11\" 404 0\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/mickume/harry_potter_tiny HTTP/11\" 200 975\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/mickume/harry_potter_tiny/resolve/75914383494871451947c4e8248fd6c643c7a3b8/README.md HTTP/11\" 200 0\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/mickume/harry_potter_tiny/resolve/75914383494871451947c4e8248fd6c643c7a3b8/.huggingface.yaml HTTP/11\" 404 0\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://datasets-server.huggingface.co:443 \"GET /info?dataset=mickume/harry_potter_tiny HTTP/11\" 200 None\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/mickume/harry_potter_tiny/revision/75914383494871451947c4e8248fd6c643c7a3b8 HTTP/11\" 200 975\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/mickume/harry_potter_tiny/tree/75914383494871451947c4e8248fd6c643c7a3b8?recursive=False&expand=False HTTP/11\" 200 290\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/mickume/harry_potter_tiny/paths-info/75914383494871451947c4e8248fd6c643c7a3b8 HTTP/11\" 200 281\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/mickume/harry_potter_tiny/tree/75914383494871451947c4e8248fd6c643c7a3b8/data?recursive=False&expand=False HTTP/11\" 200 253\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"GET /api/datasets/mickume/harry_potter_tiny/revision/75914383494871451947c4e8248fd6c643c7a3b8 HTTP/11\" 200 975\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /datasets/mickume/harry_potter_tiny/resolve/75914383494871451947c4e8248fd6c643c7a3b8/dataset_infos.json HTTP/11\" 404 0\n",
      "2024-08-21 17:00:35 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"POST /api/datasets/mickume/harry_potter_tiny/paths-info/75914383494871451947c4e8248fd6c643c7a3b8 HTTP/11\" 200 281\n",
      "2024-08-21 17:00:35 filelock DEBUG    Attempting to acquire lock 139826369590288 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_mickume___harry_potter_tiny_default_0.0.0_75914383494871451947c4e8248fd6c643c7a3b8.lock\n",
      "2024-08-21 17:00:35 filelock DEBUG    Lock 139826369590288 acquired on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_mickume___harry_potter_tiny_default_0.0.0_75914383494871451947c4e8248fd6c643c7a3b8.lock\n",
      "2024-08-21 17:00:35 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/mickume___harry_potter_tiny/default/0.0.0/75914383494871451947c4e8248fd6c643c7a3b8/dataset_info.json\n",
      "2024-08-21 17:00:35 filelock DEBUG    Attempting to release lock 139826369590288 on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_mickume___harry_potter_tiny_default_0.0.0_75914383494871451947c4e8248fd6c643c7a3b8.lock\n",
      "2024-08-21 17:00:35 filelock DEBUG    Lock 139826369590288 released on /home/local_arnab/.cache/huggingface/datasets/_home_local_arnab_.cache_huggingface_datasets_mickume___harry_potter_tiny_default_0.0.0_75914383494871451947c4e8248fd6c643c7a3b8.lock\n",
      "2024-08-21 17:00:35 filelock DEBUG    Attempting to acquire lock 139822067734992 on /home/local_arnab/.cache/huggingface/datasets/mickume___harry_potter_tiny/default/0.0.0/75914383494871451947c4e8248fd6c643c7a3b8_builder.lock\n",
      "2024-08-21 17:00:35 filelock DEBUG    Lock 139822067734992 acquired on /home/local_arnab/.cache/huggingface/datasets/mickume___harry_potter_tiny/default/0.0.0/75914383494871451947c4e8248fd6c643c7a3b8_builder.lock\n",
      "2024-08-21 17:00:35 fsspec.local DEBUG    open file: /home/local_arnab/.cache/huggingface/datasets/mickume___harry_potter_tiny/default/0.0.0/75914383494871451947c4e8248fd6c643c7a3b8/dataset_info.json\n",
      "2024-08-21 17:00:35 filelock DEBUG    Attempting to release lock 139822067734992 on /home/local_arnab/.cache/huggingface/datasets/mickume___harry_potter_tiny/default/0.0.0/75914383494871451947c4e8248fd6c643c7a3b8_builder.lock\n",
      "2024-08-21 17:00:35 filelock DEBUG    Lock 139822067734992 released on /home/local_arnab/.cache/huggingface/datasets/mickume___harry_potter_tiny/default/0.0.0/75914383494871451947c4e8248fd6c643c7a3b8_builder.lock\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\"RUN!\" Harry yelled, grabbing at her robes. Hermione’s feet hit the hard ground, running in tandem to her heartbeat as the prophecies shattered around them. With each dropped prophecy, the voices began whispering into the dark, speaking over one-another in a cacophony as Lucius Malfoy yelled for pursuit.\\xa0',\n",
       " 'A death eater appeared beside them and Hermione screamed, watching as Harry elbowed him in the face. She could hear more yelling, screaming against the rising cacophony as shelves began shuddering from the impact of their spells, knocking into one-another.\\xa0',\n",
       " 'Looking over shoulder, she glanced as another Death Eater appeared, reaching out to grab at Harry’s shoulder as the wand pulled back, a curse almost spoken––\"Stupefy!\" She yelled and watched as the Death Eater froze, his wand’s light dying like a candle blown out.',\n",
       " 'They ran on, Neville wheezing for breath beside her. \"Come on,\" she said, grabbing him. \"Come on, we have to––\" Neville threw a stupefy behind her and with a thud, she heard the spell hit its target. Without looking back she smiled and tugged him further, up to where Harry was entering the doorway.',\n",
       " 'Neville entered first and then her, and Harry turned, pressing the door shut behind them. Turning quickly, Hermione rose her wand and gasped, \"Colloportus!\" Satisfied when the door sealed itself with a squelching noise.\\xa0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from src.utils import experiment_utils\n",
    "experiment_utils.set_seed(123456)\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"mickume/harry_potter_tiny\")\n",
    "dataset[\"train\"][:5][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:16,  5.99it/s]\n"
     ]
    }
   ],
   "source": [
    "relu = torch.nn.ReLU()\n",
    "\n",
    "cache_dir = os.path.join(\n",
    "    env_utils.DEFAULT_RESULTS_DIR,\n",
    "    \"sae_mixtures\",\n",
    "    model_data_dir,\n",
    ")\n",
    "\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "from src.models import prepare_input\n",
    "from src.functional import get_module_nnsight, free_gpu_cache\n",
    "\n",
    "limit = 100\n",
    "context_limit = 1024\n",
    "\n",
    "sae_layer_name = mt.layer_name_format.format(mt.n_layer // 2)\n",
    "\n",
    "for doc_index, doc in tqdm(enumerate(dataset[\"train\"][:limit][\"text\"])):\n",
    "    inputs = prepare_input(\n",
    "        prompts = doc,\n",
    "        tokenizer = mt\n",
    "    )\n",
    "    if inputs[\"input_ids\"].shape[1] > context_limit:\n",
    "        inputs[\"input_ids\"] = inputs[\"input_ids\"][:, :context_limit]\n",
    "        inputs[\"attention_mask\"] = inputs[\"attention_mask\"][:, :context_limit]\n",
    "\n",
    "    # print(f\"{doc=}\")\n",
    "    # logger.info(inputs[\"input_ids\"].shape)\n",
    "\n",
    "    with mt.trace(inputs, scan = False, validate = False) as trace:\n",
    "        module = get_module_nnsight(mt, sae_layer_name)\n",
    "        sae_input = module.output[0].save()\n",
    "    \n",
    "    sae_mixture = relu(sae.encoder(sae_input))\n",
    "    # logger.info(f\"{sae_input.shape=} | {sae_mixture.shape=}\")\n",
    "\n",
    "    cache = {\n",
    "        \"layer\": sae_layer_name,\n",
    "        \"doc\": doc,\n",
    "        \"sae_input\": sae_input.detach().cpu().numpy().astype(np.float32),\n",
    "        \"sae_mixture\": sae_mixture.detach().cpu().numpy().astype(np.float32),\n",
    "    }\n",
    "\n",
    "    cache_path = os.path.join(cache_dir, f\"{doc_index}\")\n",
    "    np.savez_compressed(cache_path, **cache)\n",
    "\n",
    "    free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 52, 4096), (1, 52, 1024))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sae_path = \"/home/local_arnab/Codes/sae/results/sae_mixtures/pythia-410m/TinyStories/4.npz\"\n",
    "\n",
    "file = np.load(sae_path)\n",
    "file[\"sae_mixture\"].shape, file[\"sae_input\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReLU\n\u001b[1;32m      2\u001b[0m relu \u001b[38;5;241m=\u001b[39m ReLU()\n\u001b[0;32m----> 3\u001b[0m relu(\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mTensor(file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msae_mixture\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.nn import ReLU\n",
    "relu = ReLU()\n",
    "relu(torch.Tensor(file[\"sae_mixture\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
